이번 챕터에서는 속성이 여러 개일 때 선형 회귀를 하는 다중 선형 회귀에 대해서 알아봤는데요. 마찬가지로 배운 내용을 코드로 구현하기 쉽게 바꾸는 것을 해보겠습니다.

## 입력 변수와 파라미터 표현

먼저 입력 변수를 표현하는 방법입니다. 속성이 하나일 때는 모든 데이터를 하나의 벡터로

![image](https://user-images.githubusercontent.com/64893709/131304915-1d1590cb-8b88-47b1-bd96-1a81e1284fc1.png)

위와 같이 표현했습니다. 다중 선형 회귀에서는 이 방법을 바꿉니다.   
기본적으로 한 열에 하나의 데이터를 표현하는 것은 똑같고, 아래와 같이 표현할 수 있습니다.

![image](https://user-images.githubusercontent.com/64893709/131305053-fc3aeec8-d4f1-4deb-bfda-c7f6ed355061.png)

오른쪽 위에 있는 숫자는 몇 번째 데이터 인지를, 그리고 오른 쪽 아래에 있는 숫자는 몇 번째 속성인지를 나타냅니다.

1열에는 첫 번째 데이터가, 2열에는 두 번째 데이터가 저장돼있습니다.

첫 번째 행에는 0 번째 속성, 1이 저장됩니다. 보통 선형 회귀의 가설 함수를

![image](https://user-images.githubusercontent.com/64893709/131305260-4bd328a3-a5a8-4195-9cc5-41b74c7b44cd.png)

이렇게 표현하는데요. 0 번째 속성이 없긴 하지만 행렬로 표현할 때는 표현을 좀 더 통일성 있게 하기 위해서 가상의 0 번째 속성 x0를 만들고, 값을 항상 1로 설정합니다.

![image](https://user-images.githubusercontent.com/64893709/131305362-4428ea75-2704-4cbb-ae6d-3249135350d5.png)

그리고 두 번째 행에 첫 번째 속성이, 세 번째 행 두 번째 속성이... 이렇게 들어가게 됩니다. 그러면 모든 데이터를 하나의 행렬 X에 묶어서 표현할 수 있습니다. 이렇게 입력 변수 데이터를 행렬로 묶어서 표현한 것을 설계행렬, 영어로는 Design Matrix라고 합니다.

Θ 값들도 두 개에서 그 이상으로 넘어갈 때 1부터 n까지의 모든 Θ값들을 묶어서 아래와 같이 하나의 벡터로 표현합니다.

![image](https://user-images.githubusercontent.com/64893709/131305599-e78cb20a-2c5d-4bdb-8cce-058919c052d3.png)

## 모든 데이터 예측 값

가설 함수를 행렬 연산에서 어떻게 표현할 수 있는지 알아보겠습니다. 위에서 한 것처럼 입력 변수와 파라미터를

![image](https://user-images.githubusercontent.com/64893709/131305679-fea741a6-1bd3-4d18-9614-b8c8b5e09cfe.png)

위와 같이 표현하면 모든 데이터에 대한 에측 값은 두 행렬의 곱으로 나타낼 수 있습니다.

![image](https://user-images.githubusercontent.com/64893709/131305741-1fcd266c-834f-442e-96aa-e98d2ba8a462.png)

각 열에 각 데이터에 대한 예측값이 계산 될 것을 확인할 수 있습니다.

## 예측 오차

각 데이터의 목표 변수는 값이 하나기 때문에 단일 변수 선형 회귀와 마찬가지로

![image](https://user-images.githubusercontent.com/64893709/131305947-26bf8b65-679b-431b-8c7c-771119fccbc5.png)

위와 같이 표현할 수 있습니다.

![image](https://user-images.githubusercontent.com/64893709/131305989-376abd69-6ab1-4201-af0c-8d4cdcf21505.png)

모든 예측 값들과 목표 변수의 차이를 간단한 행렬 연산으로 구할 수 있는 겁니다. 뒤에서는 표현하기 쉽게 이 값을 error라고 부르겠습니다.

![image](https://user-images.githubusercontent.com/64893709/131306091-41a51b1b-3e8c-4b6d-b9f5-a202711af602.png)

## 경사 하강법

강의에서 다중 선형 회귀도 일반 선형 회귀와 마찬가지로 0부터 n까지의 θ 값들을 아래와 같이 업데이트 한다고 했습니다. (α는 학습률, m은 데이터 개수)

![image](https://user-images.githubusercontent.com/64893709/131306488-5f8923d2-bd86-42ca-96be-0df0f3840fa4.png)

이 부분도 행렬 연산을 사용하면 훨씬 더 짧고 간결하게 표현할 수 있습니다.

위에서 헀던 것처럼 입력 변수, 파라미터, 예측값 오차를 아래와 같이

![image](https://user-images.githubusercontent.com/64893709/131306638-8b95a176-09de-42b5-b88a-24f9d3cb39a8.png)

표현할 때, 똑같은 경사 하강법 공식을 간단한 행렬 연산으로 아래와 같이 나타낼 수 있습니다.

![image](https://user-images.githubusercontent.com/64893709/131307030-1929a989-9e3a-4630-a283-c796c5efe850.png)

위와 같이 나오는 이유를 확인해보겠습니다.

![image](https://user-images.githubusercontent.com/64893709/131307074-06de3b56-0ff2-44cf-bbd2-613b27b25099.png)

![image](https://user-images.githubusercontent.com/64893709/131307092-69cd66ca-4e8e-46b5-a3b6-38253078e8c0.png)

위의 계산 결과를 통해

![image](https://user-images.githubusercontent.com/64893709/131307333-f3667fee-1b29-47d4-a792-43b45d027fa5.png)

경사 하강법 공식을 위와 같은 간단한 행렬식으로 표현할 수 있는 겁니다. 행렬식으로 표현할 수 있기만 하면 numpy를 이용해서 수학식들을 쉽게 구현할 수 있습니다.
