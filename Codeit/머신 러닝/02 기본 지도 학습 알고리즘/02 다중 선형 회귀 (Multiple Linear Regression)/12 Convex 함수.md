저번과 이번 챕터에서는 경사 하강법, 그리고 정규 방정식을 이용해서 선형과 다중 회귀 손실함수를 최소화하는 방법을 배웠습니다.

손실함수 J(θ)의 경사를 구한 뒤에 이걸 이용해서 최솟값을 갖는 θ를 찾았습니다.
그런데 단순히 경사 하강법과 정규 방정식만 이용하면 항상 손실 함수의 최소 지점을 찾을 수 있을까요.

아래와 같은 함수에서 경사 하강법을 한다고 가정해보겠습니다.

![image](https://user-images.githubusercontent.com/64893709/142201115-77ca262f-43f2-4f7e-8557-e844e314937d.png)

이 지점에서 시작해서 경사를 따라 쭉 내려갑니다. 
내려가다 보면 어느 순간 여러 극소값 중 하나에 옵니다.
그럼 여기서는 경사가 0이어서 경사 하강이 종료되는데요.
그러면 손실 함수의 최저점을 찾아갈 수가 없습니다.

정규 방정식도 마찬가지입니다.

![image](https://user-images.githubusercontent.com/64893709/142201298-8baef542-0e04-4cbf-ae1c-6c7fb737afc5.png)

위와 같이 수많은 극소값들과 극대값들이 있으면 아무리 방정식을 해결해도 구한 수많은 지점 중에서 어떤 지점이 최소점인지를 알 수 없습니다.
이 모든 지점들이 경사가 0이기 때문입니다.

그러므로 함수가 이런 식으로 생긴 경우에는 경사 하강법과 정규 방정식을 통해서 구한 극소 지점이 손실 함수 전체에서 최소 지점이라고 확실하게 얘기할 ㅅ ㅜ없습니다.

반대로 손실 함수가 이렇게 생겼다고 합시다.

![image](https://user-images.githubusercontent.com/64893709/142201495-e49d9dbd-d22e-4ab3-b4de-803a86948fea.png)

위 함수는 어떤 지점에서 경사 하강을 시작해도 항상 손실 함수의 최소 지점을 찾을 수 있고, 정규 방정식을 이용해서 최소점을 구할 수 있습니다. 

위와 같은 함수를 convex 함수(아래로 볼록한 함수)라고 부릅니다.

convex 함수에서는 항상 경사 하강법이나 정규 방정식을 이용해서 최소점을 구할 수 있는 반면, 노트 위에서 봤던 non-convex 함수에서는 구한 극소저점이 최소점이라고 확신할 수 없습니다.

### 선형 회귀의 평균 제곱 오차

선형 회귀에서는 가정 함수의 예측값들과 실체 목표 변수들의 평균 제곱 오차(MSE)를 손실 함수로 사용했습니다.
다행히 선형 회귀 손실 함수로 사용하는 MSE는 항상 convex 함수입니다.
그러니까 선형 회귀를 할 때는 경사 하강법을 하거나 정규 방정식을 하거나 항상 최적의 θ 값들을 구할 수 있는 겁니다.
