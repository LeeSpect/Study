저번 챕터에서 배웠던 내용을 복습하겠습니다.

아래와 같이 데이터가 있다고 가정하면 우리가 선형 회귀로 하려는 것은, 이 데이터에 최대한 잘 맞는 어떤 선을 찾는 것입니다.

![image](https://user-images.githubusercontent.com/64893709/131221745-ea7ca4e2-3702-4e86-86a6-512c10f286a9.png)

위의 그 선을 최적선이라고 하고 이 최적선을 찾기 위해서 시도해보는 선 하나하나를 가설 함수라고 합니다.

그런데 가설 함수가 얼마나 좋은지, 그리고 어떻게 개선해야 할지 알기 위해서는 **손실 함수**를 사용합니다.   
선형 회귀에서 손실 함수는 이렇게 생겼습니다.

![image](https://user-images.githubusercontent.com/64893709/131221784-218324f0-ec53-419d-a68e-46a29df3b61b.png)

보시다시피 손실 함수는 θ에 대한 함수힙니다.   
가설 함수가 어떤 θ값을 쓰냐에 따라 이 손실 함수의 결과가 달라지는 것입니다.

손실 함수의 결과값이 크다는 것은 손실이 크다는 것이기 때문에 좋지 않은 가설 함수입니다.   
반대로 손실 함수의 결괏값이 작으면 손실이 작다는 것이기 때문에 좋은 가설 함수 입니다.

![image](https://user-images.githubusercontent.com/64893709/131221796-12ddc201-3e46-4749-9247-63d76317f5d3.png)

선형 회귀에서 하려는 것은 Θ값들을 잘 선택해서 이 손실 함수의 결괏값을 최대한 작게 만드는 것입니다.

![image](https://user-images.githubusercontent.com/64893709/131221840-163bfc7b-4411-4238-8e9b-eb4bd4e831a6.png)

이 방법 중 하나로 경사 하강법이라는 것이 있습니다. 경사 하강법은 손실 함수의 아웃풋을 낮추기 위해서 가장 가파르게 내려가는 방향으로 계속해서 이동하는 것입니다.

즉, 손실을 가장 빠르게 줄일 수 있는 방향으로 θ값들을 수정하는 것입니다.   
지금까지의 내용은 모두 저번 챕터에서 했던 내용인데, 그렇다면 다중 선형 회귀에서는 어떻게 할 수 있을까요?

시각적으로 표현하기는 어렵지만 수학적으로는 거의 같다고 보면 됩니다.

![image](https://user-images.githubusercontent.com/64893709/131222196-aad25919-3876-4ef6-bd46-654dd7c85548.png)

다중 선형 회귀에서도 손실 함수가 똑같이 생겼습니다.   
다중 선형 회귀에서는 입력 변수가 여러 개이기 때문에, 가설 함수가 살짝 달라지지만 손실 함수는 완전히 똑같습니다.

그리고 저번 챕터에서 했던 것처럼 손실을 줄이기 위해서 경사 하강법을 해야 하는데요.   
입력 변수가 하나일 때와는 어떤 차이가 있을까요?

입력 변수가 하나일 때는 θ0과 θ1만 업데이트하면 되죠?

이렇게 하면 됩니다.

![image](https://user-images.githubusercontent.com/64893709/131222217-35c31736-68e4-44a5-86bf-d0b3ff17828e.png)

여기서 우리가 하는 것은 손실을 가장 빨리 줄일 수 있는 방향으로 θ값들을 수정하는 것인데, 이 부분은 이전 챕터에서 복습할 수 있습니다.

암튼 입력 변수가 하나일 때는 이렇게 하면 되는데요. 입력 변수가 여러 개면 θ값도 여러 개죠?   
그러면 그냥 업데이트할 θ값이 많아지는 것 뿐입니다.

![image](https://user-images.githubusercontent.com/64893709/131222234-8dd2f5fb-195a-47b5-a716-ef6913e0ae2f.png)

입력 변수가 n개 있다고 하면 θ0부터 θn까지 쭉 업데이트를 해야 경사 하강을 한 번 했다고 할 수 있습니다.

이렇게 쭉 나열되어 있는 것을 하나의 식으로 표현한다면

![image](https://user-images.githubusercontent.com/64893709/131222244-2e94ed4b-41a3-4445-8632-17b90b812cde.png)

이렇게 할 수 있는데요.

J에 0을 넣어서 업데이트하고 J에 1을 넣어서 업데이트하고... 이런 식으로 J에 1부터 n까지 넣어서 모든 θ값들을 업데이트하는 겁니다.

이 과정을 한 번 거칠 때마다 손실을 최대한 빨리 감소시키는 방향으로 θ값들이 업데이트 되는 것입니다.

![image](https://user-images.githubusercontent.com/64893709/131222267-4fd226c7-8a8d-44f6-bcdf-80d2496ed3a4.png)

이것을 충분히 반복하면 결국 손실을 최소에 가깝게 줄일 수 있습니다.   
그러면 학습 데이터에 잘 맞는 θ값들을 찾게 되는데요.   
데이터에 잘 맞는 가설 함수를 찾았다고 할 수 있는 겁니다.
