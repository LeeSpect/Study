우리는 계속해서 세타 값을 조율하면서 더 좋은 가설 함수를 만들려고 하고, 결국에는 데이터에 가장 잘 맞는 최적선을 찾으려고 합니다.

가설 함수는 세상에 일어나는 상황을 수학적으로 표현한다는 의미에서 '모델'이라고 부릅니다. 

앞으로 머신 러닝을 하다 보면 '모델'이라는 용어를 자주 접하게 될 겁니다. 그리고 데이터를 이용해서 모델을 개선시키는 걸 '모델을 학습시킨다'라고 할 겁니다.

## 모델의 평가

우리는 선형 회귀 모델을 학습시켜서, 우리 나름대로 최적선이라고 생각하는 이런 가설 함수가나왔다고 합시다.

![image](https://user-images.githubusercontent.com/64893709/117116097-e27f7380-adc8-11eb-963f-2add1be83130.png)

자, 그런데 모델을 학습시키고 나서는 이 모델이 얼마나 좋은지 평가를 해야 합니다. 그러니까 이 모델이 결과를 얼마나 정확히 에측하는지를 평가해야 한다는 거죠.

#### RMSE

이때 많이 쓰는 게 '평균 제곱근 오차', 영어로는 'root mean square error', 줄여서 'RMSE'입니다.

그냥 전에 배웠던 평균 제곱 오차에 루트를 한 건데요. 루트를 왜 하는 걸까요? 만약 우리가 집 가격을 예측한다고 하면, 목표 변수의 단위는 '원'이잖아요? 그런데 오차 제곱을 하면 단위가 '원 제곱'이 됩니다. 별로와 닿지 않는 단위기 때문에, 마지막에 루트를 해서 다시 단위를 '원'으로 만들어 주는 겁니다.

#### Training Set vs. Test Set

학습시킨 모델, 즉 우리가 찾은 최적선을 우리 데이터랑 비교해서 평균 제곱근 오차를 구하면 되겠죠?

그런데 함정이 있습니다. 우리는 이 데이터에 맞게끔 모델을 학습시켰으니까, 평균 제곱근 오차가 낮게 나오는 건 어떻게 보면 너무 당연한 겁니다.

그렇다면 어떻게 해야 좀 더 신빙성 있게 모델을 평가할 수 있을까요?

보통은 모델을 학습시키기 위한 데이터와 모델을 평가하기 위한 데이터를 따로 분리합니다.

![image](https://user-images.githubusercontent.com/64893709/117117062-0db69280-adca-11eb-91df-b1ae3bb88e9e.png)

데이터가 이렇게 30개 있다고 가정합시다. 그러면 이 30개를 다 학슶시키기 위해 사용하는 게 아니라 24개, 6개 이런 식으로 나눕니다. 24개는 모델을 학습시키기 위해 쓰고(주황색), 6개는 모델을 평가하기 위해 쓰는 겁니다(보라색). 모델을 학습시키기 위해 쓰는 데이터셋을 'training set'이라고 합니다. 모델을 평가하기 위햇 쓰는 데이터셋을 'test set'이라고 합니다.

과정을 처음부터 보자면, 우선 training set의 24개 주황색 데이터를 통해 모델을 학습시켜서, 이 데이터에 가장 잘 맞는 최적선을 구합니다. 그리고 이 최적선을 training set이 아닌 test set의 보라색 데이터 6개와 놓고 평가하는 겁니다. 지금의 경우에는 평균 제곱근 오차를 게산해서 평가하는 겁니다.

이렇게 하면 학습에 사용된 데이터와 평가에 사용된 뎅터가 따로니까, 좀 더 신빙성 있게 우리의 모델을 평가할 수 있겠죠?
